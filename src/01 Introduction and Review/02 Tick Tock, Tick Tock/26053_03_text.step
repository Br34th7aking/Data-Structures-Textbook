{"id": "95853", "block": {"feedback_correct": "", "name": "text", "feedback_wrong": "", "text": "<p>There are three main notations to describe time complexity:\u00a0<b><span class=\"wysiwyg-color-green\">Big-O</span></b> (\"Big-Oh\"),\u00a0<b><span class=\"wysiwyg-color-blue\">Big-\u03a9</span></b> (\"Big-Omega\"), and\u00a0<b><span class=\"wysiwyg-color-purple\">Big-\u03f4</span></b> (\"Big-Theta\"). <b><span class=\"wysiwyg-color-green\">Big-O</span></b> notation provides an <b><span class=\"wysiwyg-color-green\">upper-bound</span></b> on the number of operations performed, <b><span class=\"wysiwyg-color-blue\">Big-\u03a9</span></b> provides a <b><span class=\"wysiwyg-color-blue\">lower-bound</span></b>, and <b><span class=\"wysiwyg-color-purple\">Big-\u03f4</span></b> provides both <b><span class=\"wysiwyg-color-purple\">an upper-bound </span></b><b><i><span class=\"wysiwyg-color-purple\">and</span></i><span class=\"wysiwyg-color-purple\"> a lower-bound</span><i></i></b>. In other words, \n\n<b><span class=\"wysiwyg-color-purple\">Big-\u03f4</span></b>\u00a0implies <i>both</i> <b><span class=\"wysiwyg-color-green\">Big-O</span></b> <i><b>and</b></i> \n\n<b><span class=\"wysiwyg-color-blue\">Big-\u03a9</span></b>. For our purposes, we will only consider Big-O notation because, in general, we only care about upper-bounds on our algorithms.</p><p>Let\u00a0<i>f</i>(<i>n</i>) and\u00a0<i>g</i>(<i>n</i>) be two functions defined for the real numbers. One would write</p><p class=\"wysiwyg-text-align-center\"><i><b></b>$ f(n) = \\mathcal{O}(g(n)) $<span></span><span></span><b></b></i><br></p><p>if and only if there exists some constant\u00a0<b><i></i></b><i>c</i> and some real\u00a0<i>n</i>\u2080 such that the absolute value of\u00a0<i>f</i>(<i>n</i>) is at most <i>c</i> multiplied by the absolute value of\u00a0<i>g</i>(<i>n</i>) for all values of\u00a0<i>n</i> greater than or equal to\u00a0<i>n</i>\u2080. In other words, such that</p><p class=\"wysiwyg-text-align-center\">$ |f(n)| \\leq c|g(n)| $\u00a0for all $ n \\geq n_0 $\u00a0</p><p class=\"wysiwyg-text-align-left\">Also, note that, for all three notations, we drop all lower functions when we write out the complexity. Mathematically, say we have two functions\u00a0<i>g</i>(<i>n</i>) and\u00a0<i>h</i>(<i>n</i>), where</p><p class=\"wysiwyg-text-align-center\">$|g(n)| \\gt |h(n)|$\u00a0for all\u00a0$ n \\geq n_0 $\u00a0<br></p><p class=\"wysiwyg-text-align-left\">If we have a function <i>f</i>(<i>n</i>) that is O(<i>g</i>(<i>n</i>) + <i>h</i>(<i>n</i>)), we would just write that\u00a0<i>f</i>(<i>n</i>) is O(<i>g</i>(<i>n</i>)) to simplify.</p><p class=\"wysiwyg-text-align-left\">Note that we only care about time complexities with regard to large values of\u00a0<i>n</i>, so when you think of algorithm performance in terms of any of these three notations, you should really only think about how the algorithm scales as\u00a0<i>n</i>\ufeff approaches infinity.</p>", "subtitle_files": [], "source": null, "animation": null, "video": null, "tests_archive": null, "options": {}, "subtitles": {}}, "time": "2017-06-08T22:30:04.932200"}