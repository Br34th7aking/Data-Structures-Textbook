{"id": "121621", "block": {"feedback_correct": "", "name": "text", "feedback_wrong": "", "text": "<p>As you can see, we further improved our <b>average-case</b>\u00a0performance by using a\u00a0<b><span class=\"wysiwyg-color-purple\">Hash Table</span></b>\u00a0to implement our lexicon. We have to perform a\u00a0<b>O(<i>k</i>)</b> operation on each word in our lexicon (where\u00a0<i>k</i> is the length of the word) in order to compute the word's hash value, so we say that our\u00a0<b>average-case time complexity</b> is\u00a0<b>O(1)</b> if we don't take into account the hash function or\u00a0<b>O(<i>k</i>)</b> if we do take into account the hash function.</p><p>However, keep in mind that the order in which elements are stored in a\u00a0<b><span class=\"wysiwyg-color-purple\">Hash Table's</span></b> backing array does not necessarily have any meaning. In other words, it is impossible for us to iterate through the elements of a\u00a0<b><span class=\"wysiwyg-color-purple\">Hash Table</span></b> in a meaningful (e.g. alphabetical) order.</p><p>In terms of memory efficiency, recall that, with a\u00a0<b><span class=\"wysiwyg-color-purple\">Hash Table</span></b>, we try to maintain the\u00a0<b>load factor</b> (i.e., the percentage full the backing array is at any given moment) relatively low. Specifically, ~70% is typically a good number. Formally,\u00a0because we will have allocated approximately\u00a0$ m=\\frac{n}{0.7} $\u00a0slots to store\u00a0<i>n</i> elements, because\u00a0$ \\frac{1}{0.7} $\u00a0is a constant, our\u00a0<b>space complexity</b> is\u00a0<b>O(<i>n</i>)</b>. However, even though the space usage scales linearly, note that we will always be wasting approximately 30% of the space we allocate, which can be a pretty big cost as our dataset gets large (30% of a big number is a smaller, but still big, number).</p><p>Also, note that, by simply using a\u00a0<b><span class=\"wysiwyg-color-green\">Hash Map</span></b> instead of a\u00a0<b><span class=\"wysiwyg-color-purple\">Hash Table</span></b>, we were able to create a <i>dictionary</i> that stores (<i>word</i>,\u00a0<i>definition</i>) pairs as opposed to a <i>lexicon</i> that only stores\u00a0<i>words</i>. As a result, we have the added functionality of being able to find a word's definition in addition to simply seeing if a word exists, but without worsening our performance. It should be noted that we could have theoretically made somewhat trivial modifications to any of the previous (and to any of the upcoming) implementation strategies to store a\u00a0<i>dictionary</i> instead of a\u00a0<i>lexicon</i> (i.e., simply store (<i>word</i>,\u00a0<i>definition</i>) pairs in our data structure, but perform all searching algorithms using just the\u00a0<i>word</i>\ufeff), but we wouldn't be able to use existing C++ data structure implementations: we would need to implement our own from scratch, which can be a pain.</p><p>Because we have to compute the hash values of our strings, we can safely say that the time complexity of this implementation approach is\u00a0<b>O(<i>k</i>)</b>\u00a0in the\u00a0<b><i>average</i> case</b>. Is there some way to make this O(<i>k</i>) time complexity a\u00a0<i>worst</i>-case time complexity? Also, can we somehow gain the ability to iterate through our elements in alphabetical order? In the next section, we will discuss the\u00a0<b><span class=\"wysiwyg-color-red\">Multiway Trie</span></b>, a data structure that allows us to obtain both.</p>", "subtitle_files": [], "source": null, "animation": null, "video": null, "tests_archive": null, "options": {}, "subtitles": {}}, "time": "2016-09-05T17:14:18.667305"}