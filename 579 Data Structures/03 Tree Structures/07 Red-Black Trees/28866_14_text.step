{"block": {"tests_archive": null, "feedback_correct": "", "subtitle_files": [], "text": "<p>With this, we have concluded our discussion regarding the various types of\u00a0<b><span class=\"wysiwyg-color-green\">Binary Search Trees</span></b>. It was quite a lengthy discussion, so below is a brief recap of what we covered.</p><p>We first introduced the\u00a0<b><span class=\"wysiwyg-color-green\">Binary Search Tree</span></b>, a binary tree in which, for any node\u00a0<i>u</i>, all nodes in\u00a0<i>u</i>'s left subtree are smaller than\u00a0<i>u</i> and all nodes in\u00a0<i>u</i>'s right subtree are larger than\u00a0<i>u</i>. With this property, for balanced trees, we would be able to achieve an O(log\u00a0<i>n</i>) time complexity for finding, inserting, and removing elements. We were able to formally prove that, although the <b>worst-case</b> time complexity of the three operations of a <b><span class=\"wysiwyg-color-green\">Binary Search Tree</span></b> is\u00a0<b>O(<i>n</i>)</b>,\u00a0under some assumptions of randomness, the\u00a0<b>average-case</b> time complexity is\u00a0<b>O(log\u00a0<i>n</i>)</b>. However, we also noted that the assumptions of randomness we made were somewhat unreasonable with real data.</p><p>Then, to remedy the unreasonable nature of our assumptions we made when we proved the O(log\u00a0<i>n</i>) average-case time complexity of a\u00a0<b><span class=\"wysiwyg-color-green\">Binary Search Tree</span></b>, we introduced the\u00a0<b><span class=\"wysiwyg-color-blue\">Randomized Search Tree</span></b>, a special kind of\u00a0<b>Treap</b> in which <i>keys</i> are the elements we would have inserted into a regular\u00a0<b><span class=\"wysiwyg-color-green\">Binary Search Tree</span></b> and\u00a0<i>priorities</i> are randomly-generated integers. Even though we didn't explicitly go over the formal proof in this text, it can be formally proven that a\u00a0<b><span class=\"wysiwyg-color-blue\">Randomized Search Tree</span></b> does indeed simulate the same random distribution of tree shapes that came about from the assumptions of randomness we made in our formal proof for the O(log\u00a0<i>n</i>) average-case time complexity. However, even though we explored a data structure that could actually obtain the\u00a0<b>average-case O(log\u00a0<i>n</i>)</b> time complexity we wanted, we were still stuck with the original\u00a0<b>O(<i>n</i>) worst-case</b> time complexity.</p><p>To speed things up even further, we introduced the\u00a0<b><span class=\"wysiwyg-color-purple\">AVL Tree</span></b> and the\u00a0<b><span class=\"wysiwyg-color-red\">Red-Black Tree</span></b>, two self-balancing\u00a0<b><span class=\"wysiwyg-color-green\">Binary Search Tree</span></b> structures that were guaranteed to have a\u00a0<b>worst-case</b> time complexity of\u00a0<b>O(log <i>n</i>)</b>. The balance restrictions of the\u00a0<b><span class=\"wysiwyg-color-purple\">AVL Tree</span></b> are stricter than those of the\u00a0<b><span class=\"wysiwyg-color-red\">Red-Black Tree</span></b>, so even though the two data structures have the same <i>time complexities</i>, in practice,\u00a0<b><span class=\"wysiwyg-color-purple\">AVL Trees</span></b> are typically faster with find operations (because they are forced to be more balanced, so traversing down the tree without modifying it is faster) and\u00a0<b><span class=\"wysiwyg-color-red\">\ufeffRed-Black Trees</span></b><span class=\"wysiwyg-color-red\"></span> are typically faster with insertion and removal operations (because they are not required to be as balanced, so they perform less operations to maintain balance after modification).</p>", "feedback_wrong": "", "options": {}, "subtitles": {}, "name": "text", "source": null, "video": null, "animation": null}, "time": "2016-09-11T01:08:28.008249", "id": "120944"}