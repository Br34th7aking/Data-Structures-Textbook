{"id": "110140", "block": {"feedback_correct": "", "name": "text", "feedback_wrong": "", "text": "<p>Recall from statistics that the expected value of a discrete random variable\u00a0<i>X</i> is simply\u00a0$ \\sum_{i=1}^{n}{p_i X_i} $, where\u00a0$ p_i $\u00a0is the probability that outcome\u00a0$ X_i $\u00a0occurs. As we mentioned before, our discrete random variable is \"depth\". In a specific <b><span class=\"wysiwyg-color-green\">BST</span></b> <i>j</i>\u00a0with\u00a0<i>n</i> nodes, the probability of searching for a node\u00a0<i>i</i>\u00a0can be denoted as\u00a0$ p_{ji} $, and the depth of node\u00a0<i>i</i> can be denoted as\u00a0$ d_{ji}$. Therefore,\u00a0\"computing the expected depth\" of a specific <b><span class=\"wysiwyg-color-green\">BST</span></b> <i>j</i>\u00a0is simply computing\u00a0$ E_j(d)=\\sum_{i=1}^{n}{p_{ji} d_{ji}} $.</p><p>Remember those two assumptions we made at the beginning? The first assumption was that\u00a0\"all <i>n</i> elements are equally likely to be searched for\". Mathematically, this means\u00a0$ p_1=p_2= ... =p_n=\\frac{1}{n}$, so,\u00a0$  E_j(d)=\\sum_{i=1}^{n}{p_{ji} d_{ji}} = \\sum_{i=1}^{n}{\\frac{1}{n} d_{ji}} = \\frac{1}{n} \\sum_{i=1}^{n}{d_{ji}}$.</p><p>Now, let's introduce yet another formal definition: let the\u00a0<b>total depth</b> of a specific <b><span class=\"wysiwyg-color-green\">BST</span></b> <i>j</i>\u00a0with\u00a0<i>n</i> nodes\u00a0be denoted as\u00a0$ D_j(n)=\\sum_{i=1}^{n}{d_{ji}} $. Thus,\u00a0$ E_j(d)=\\frac{1}{n} D_j(n) $. However, this is for a\u00a0<i>specific</i> <b><span class=\"wysiwyg-color-green\">BST</span></b> <i>j</i>, but we need to generalize for any arbitrary <b><span class=\"wysiwyg-color-green\">BST</span></b>!</p><p>Let\u00a0$ D(n) $\u00a0be the\u00a0<b>expected total depth</b> among ALL <b><span class=\"wysiwyg-color-green\">BSTs</span></b> with\u00a0<i>n</i> nodes. If we can solve\u00a0$ D(n) $, then our answer, the expected depth\u00a0of a <b><span class=\"wysiwyg-color-green\">BST</span></b> with <i>n</i> nodes,\u00a0will simply be\u00a0$ \\frac{1}{n} D(n) $\u00a0(again because of assumption 1). However, we just introduced a new term! How will we simplify our answer?</p><p>Each <b><span class=\"wysiwyg-color-green\">BST</span></b>\u00a0<i>j</i> is simply the result of insertion order\u00a0<i>j</i> (because a <b><span class=\"wysiwyg-color-green\">BST</span></b> can be defined by the order in which we inserted its elements). For the first insertion, we can insert any of our\u00a0<i>n</i> elements. For the second insertion, we can insert any of the\u00a0<i>n</i>-1 remaining elements. By this logic, there are\u00a0$ n*(n-1)*(n-2)*...=n! $\u00a0possible insertion orders. Based on our second assumption, all insertion orders are equally likely. Therefore, technically, we could rewrite\u00a0$ D(n)=\\frac{1}{n!} \\sum_{j=1}^{n!}{D_j(n)} $. But wait... Does this mean we have to enumerate all <i>n</i>!\u00a0possible <b><span class=\"wysiwyg-color-green\">BSTs</span></b> with\u00a0<i>n</i> nodes and compute the total depth of each? This naive approach sounds far too inefficient! Let's take a step back and rethink this.</p>", "subtitle_files": [], "source": null, "animation": null, "video": null, "tests_archive": null, "options": {}, "subtitles": {}}, "time": "2016-09-05T17:08:22.210712"}