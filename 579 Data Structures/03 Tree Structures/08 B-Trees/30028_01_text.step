{"block": {"video": null, "tests_archive": null, "feedback_correct": "", "animation": null, "text": "<p>As we have been introducing different tree structures and analyzing their implementations, we have actually been making an assumption that you probably overlooked as being  negligible: we have been assuming that all node accesses in memory take the same amount of time. In other words, as we traverse an arbitrary tree structure and visit a node, we assume that the time it takes to \"visit\" a node is the same for every node. In practice, is this assumption accurate?</p><p>It turns out that, unfortunately, this assumption can't <i>possibly</i> be accurate based on the way memory is organized in our computers. As you might already know (and if you don't, we'll bring you up-to-speed), memory in a computer is based on a hierarchical system as shown below:</p><p><img height=\"324\" width=\"652\" src=\"https://ucarecdn.com/70e5f385-bec6-49cd-9c0b-90a0d4adcbd9/\" alt=\"\" title=\"Image: https://ucarecdn.com/70e5f385-bec6-49cd-9c0b-90a0d4adcbd9/\"></p><p>The basic idea behind the hierarchy is that the top layers of memory\u2014colloquially referred to as the \"closest\" memory\u2014take the shortest time to access data from. Why? Partly because they are much smaller and therefore naturally take less time to traverse to find the data.\u00a0</p><p>Going back to tree traversals, consequently, if there happens to be a pointer to a node that we need to traverse that points to memory in an L2 cache, then it will take longer to traverse to that node than it would take to traverse to a node that is located in an L1 cache. Also, since pointers can point practically anywhere, this situation happens more often than you may think. How does the CPU (the Central Processing Unit) generally determine which data is placed where in memory <b>and</b> how can we take advantage of that knowledge to speed up our tree traversal <i>in practice</i>?</p><p><b><span class=\"wysiwyg-color-red\">Note:</span></b> It is a common to ask: \"Why don't we just (somehow) fit our <i>entire</i> tree structure into a fast section of memory\u2014such as an L1 cache\u2014to ensure that we have fast constant accesses across the entire tree?\" The problem with doing this is that the sections of memory that are fast (such as the caches) are actually quite small in size. Consequently, as our data structures grow in size, they will not be able to fit in such a small section of memory. You might subsequently wonder: \"Well, why don't we just make that fast section of memory bigger?\" Unfortunately, the bigger we make the memory, the slower it will be, and we don't want slower memory!<br></p>", "subtitle_files": [], "subtitles": {}, "feedback_wrong": "", "name": "text", "source": null, "options": {}}, "id": "122782", "time": "2016-09-14T00:10:36.413895"}